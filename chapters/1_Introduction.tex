\chapter{Introduction}
\begin{flushright}
    \textit{Above all, my life is research.}\\
    --- Margarita Salas
\end{flushright}

\vspace{1cm}

\section{Mathematical Modeling in Biology}
%\subsection{Overview of Mathematical Modeling in Biological Sciences}
Biological systems are extraordinarily complex, involving multifaceted interactions that span from molecules to entire ecosystems. Because traditional experimental approaches often cannot fully capture this complexity, mathematical modeling has become an indispensable tool for biologists to understand, simplify, and predict system behaviors. These models provide a structured framework for analyzing biological processes, generating hypotheses, and integrating experimental data into a coherent representation of larger systems. By offering quantitative predictions, mathematical models enable the testing of hypotheses under controlled \textit{in silico} conditions, thereby uncovering insights that might be challenging to observe directly \cite{banwarth-kuhn2020how}. Indeed, many recent biological breakthroughs are rooted in the synergy between modeling, experimental observation, and hypothesis testing \cite{servedio2014not}. Although models focus on essential features of a system to clarify underlying principles, they rely on assumptions and simplifications that can produce inaccuracies if chosen poorly \cite{brown2018evaluating}. Thus, iterative model refinement and experimental validation are vital to ensure that each model accurately represents the biological phenomenon under study.

% \subsection{Applications in Gene Regulation} \textbf{Applications in Gene Regulation.}
Mathematical modeling has had a profound impact on deciphering gene regulation, where it has become essential for unraveling the complex mechanisms of transcriptional control and gene expression. Gene regulation involves a network of interactions between transcription factors, DNA, RNA, and other cellular components, collectively determining whether a gene is activated or silenced. The emergence of high-throughput genomic technologies in the early 21$^\text{st}$ century generated a substantial amount of data, spurring new advances in modeling \cite{ay2011mathematical}. Modeling is especially important in this context because gene expression lies at the intersection of numerous biological processes; even subtle changes in regulatory interactions can drive diseases, phenotypic variation, or evolutionary novelties \cite{ay2011mathematical}. By offering a quantitative framework, mathematical models simulate regulatory networks and predict how modifications in specific components influence overall gene expression \cite{banwarth-kuhn2020how}. These models also clarify how gene expression is coordinated from the single-cell level to entire organisms, yielding a deeper comprehension of development and cellular function. A noteworthy illustration involves modeling gene regulation in early \textit{Drosophila melanogaster} embryogenesis, where spatial expression patterns are explained by reaction-diffusion principles that identify critical interactions \cite{reinitz-sharp1995mechanism, jaeger-surkova2004dynamicControl, jaeger-surkova2004dynamicAnalysis}. In synthetic biology, mathematical models guide the design of gene circuits that exhibit oscillations \cite{elowitz2000synthetic} or switch-like behaviors \cite{gardner-cantor2000}, demonstrating the broad applications of these approaches.

%\subsection{Applications in Epidemiology} \textbf{Applications in Epidemiology.}
In epidemiology, mathematical models are instrumental in studying the spread of infectious diseases and assessing the effectiveness of diverse public health interventions \cite{siettos2013mathematical}. By simulating disease transmission within populations, these models predict outbreaks, gauge the potential outcomes of vaccination strategies, and evaluate containment measures. Over the past few decades, they have become an essential component of public health policy making \cite{temime2008rising, miguelAngel2021}, proving indispensable during crises such as the 2014 Ebola outbreak in West Africa and the recent COVID-19 pandemic. By forecasting disease trajectories, modeling aids both immediate and longer-term policy decisions, including social distancing mandates and lockdown protocols. As infectious diseases continue to present urgent challenges, epidemiological modeling will remain a key instrument for understanding disease dynamics and guiding public health responses \cite{siettos2013mathematical}.

%\subsection{Applications in Evolutionary Biology} \textbf{Applications in Evolutionary Biology.}
Mathematical modeling has had also a long and influential history in evolutionary biology, where it has been essential for elucidating the mechanisms that govern genetic change. In particular, these models help address questions that are experimentally challenging due to the long timescales characterizing evolutionary processes \cite{brown2018evaluating}. They enable the exploration of natural selection, genetic drift, mutation, and migration, all of which collectively determine how genetic variation changes in populations over generations \cite{johri-aquadro2022recommendations,rosenberg-stadler-steel2025aMathematical}. By incorporating quantitative equations into evolutionary theory, researchers can predict genetic trends, evaluate the forces that drive evolution, and examine the coevolution of species or the emergence of advantageous mutations \cite{servedio2014not}. Such modeling further allows the testing of theoretical ideas about evolutionary processes, providing insights into species origins and adaptations that guide future research directions in evolutionary biology. To delve more deeply into how these processes unfold over time, it is crucial to understand evolution as a stochastic phenomenon, where random events play a significant role in shaping genetic outcomes.

\section{Evolution as a Stochastic Process}
Evolution proceeds through four fundamental processes: mutation, natural selection, genetic drift, and recombination, each of which has an inherent random component that lends itself to stochastic models \cite{Arenas2015, siepel2009}. Mutation introduces new variants at rates typically modeled by Poisson processes, whereas selection favors or disfavors certain variants based on fitness effects. Drift acts as a random sampling event that can fix or eliminate alleles regardless of fitness, especially in small populations, while recombination reorganizes genetic material to produce new haplotype combinations.

Markov models frequently capture these processes by assigning\linebreak state-dependent transition rates for sequence changes, and continuous-time Markov chains (CTMCs), for instance, quantify the instantaneous substitution rates among nucleotides or amino acids. Traditionally, these models have been used to describe the evolution of DNA sequences. Formally, a Markov chain is a stochastic process $\{X_t, t \geq 0\}$ characterized by the Markov property, which states:

\begin{equation}
P(X_{t+s} = j \mid X_t = i, X_u = x_u, u < t) = P(X_{t+s} = j \mid X_t = i)
\end{equation}
for all states $i, j$ and times $t, s \geq 0$. The process is fully described by its transition probabilities $P_{ij}(t) = P(X_{t+s}=j \mid X_s=i)$, which satisfy the Chapman-Kolmogorov equations:

\begin{equation}
P_{ij}(t+s) = \sum_{k} P_{ik}(t) P_{kj}(s), \quad \text{for all } t,s \geq 0.
\end{equation}

In a continuous-time context, transitions occur according to rates defined by a rate matrix $Q = \{q_{ij}\}$, where each off-diagonal entry $q_{ij}$ represents the instantaneous rate of moving from state $i$ to state $j$, and diagonal entries are defined such that $q_{ii} = -\sum_{j \neq i} q_{ij}$. Thus, the transition probability matrix over time $t$ can be computed through matrix exponentiation:

\begin{equation}
P(t) = e^{Qt}.
\end{equation}

To integrate Markov chains into the evolutionary model, we consider the following explanatory scheme:

\begin{enumerate}
    \item \textbf{State Definition}: Define each state of the Markov chain to represent a particular genetic configuration or nucleotide/amino acid sequence.
    \item \textbf{Transition Rates}: Specify transition rates $q_{ij}$ based on biological mechanisms such as mutation rates, selection coefficients, and drift probabilities.
    \item \textbf{Rate Matrix Construction}: Assemble the rate matrix $Q$ encapsulating all possible instantaneous transitions between genetic states.
    \item \textbf{Transition Probabilities Calculation}: Calculate transition probability matrices $P(t)$ using matrix exponentiation to predict evolutionary dynamics over time.
    \item \textbf{Integration into Phylogenetic or Population Genetic Models}: Employ these computed transition probabilities in models such as Wright-Fisher, Moran, or phylogenetic inference frameworks to estimate divergence times, genetic variability, or ancestral states.
\end{enumerate}

Although Markov models are powerful tools for describing evolutionary processes, their simplest forms make assumptions about rate homogeneity across time and states, and may fail to capture the full complexity of biological systems. For instance, as multiple generations pass, deterministic selection interacts with stochastic mutation and drift, resulting in intricate patterns of divergence. Models such as Wright-Fisher and Moran (including diffusion and coalescent extensions) offer a theoretical foundation for quantifying these random dynamics \cite{griffiths-marjoram1996}. Consequently, beneficial mutations can still be lost if chance events override selection in finite populations \cite{haldane1937effect}, illustrating how randomness profoundly influences molecular evolution.

Population genetics predominantly examines allele frequency changes within species, relying on models like Wright-Fisher or coalescent theory to incorporate drift, selection, and mutation in a finite population \cite{hein2004gene}. By tracking the probabilities of fixation or loss over discrete generations, population-genetic analyses elucidate microevolutionary dynamics, including the relative roles of neutrality and adaptation. Phylogenetics, conversely, focuses on substitutions that accumulate between diverging lineages, often modeling sequence evolution with continuous-time Markov chains along the branches of a tree. Here, each branch length reflects the expected number of substitutions per site, and likelihood-based or Bayesian methods assess different phylogenetic hypotheses \cite{KosiolGoldman2011}. Although both fields consider the same fundamental processes, they differ in timescale and scope: population genetics addresses polymorphisms within populations, while phylogenetics assumes fixed differences between species. Furthermore, recombination complicates phylogenetic inference by creating discordant gene trees, whereas in population genetics it may accelerate adaptation or break up linkage. Recent methodological advances bridge these perspectives, for instance by integrating coalescent theory into species-tree approaches that accommodate incomplete lineage sorting. Ultimately, both population genetics and phylogenetics leverage stochastic models to reconstruct evolutionary history, yet they do so with distinct focuses on the micro versus macro dimensions of biological change. To date, the two fields are complementary and not in competition. A core framework for both fields involves the molecular clock, which uses evolutionary rates to date divergence times across lineages.


\section{The Concept of the Molecular Clock}
The molecular clock hypothesis traces back to the 1960s when Zuckerkandl and Pauling observed a roughly consistent rate of molecular changes and proposed that these changes could be treated as a ``clock'' for dating evolutionary events \cite{zuckerkandl-pauling1965}. Kimura's Neutral Theory later provided theoretical support by suggesting that the majority of substitutions are selectively neutral and accumulate at a near-constant rate through genetic drift \cite{Bromham2003}. Early strict clock models treated substitutions as a Poisson process with a uniform rate across all lineages \cite{takahata2007}, but empirical evidence often contradicted this rigidity. Consequently, relaxed clocks were introduced to permit variable substitution rates across branches within a statistically coherent framework \cite{Drummond2006}. 

In a strict molecular clock framework, the accumulation of substitutions is modeled by a Poisson process. Let $N(t)$ denote the number of substitutions that occur along a lineage during a time interval $t$. Assuming a constant substitution rate $\mu$ (substitutions per unit time), the probability that exactly $k$ substitutions occur in time $t$ is given by the Poisson probability mass function:
$$
P\left(N(t) = k\right) = \frac{(\mu t)^k e^{-\mu t}}{k!}, \quad k = 0, 1, 2, \dots
$$
Here, the expected number of substitutions is
$$
\mathbb{E}[N(t)] = \mu t,
$$
and due to the properties of the Poisson distribution, the variance is also
$$
\mathbb{V}(N(t)) = \mu t.
$$
This formulation encapsulates the idea that both the mean and the variance of the substitution process increase linearly with time. However, empirical studies have noted that observed variance often exceeds the mean (overdispersion), suggesting that factors such as lineage-specific rate heterogeneity, episodic selection, and other evolutionary forces may cause deviations from the strict Poisson assumption \cite{Gillespie1984, Ho2011}. Such observations have motivated the development of relaxed clock models, which allow for rate variation among lineages while maintaining a statistically coherent framework for divergence time estimation.

Estimating these rates and divergence times typically employs likelihood or Bayesian methods, with Bayesian approaches (including MCMC in BEAST) yielding comprehensive posterior distributions of tree topology, rates, and node ages \cite{Kumar2016}. Nonetheless, current models exhibit inherent limitations: lineage rate heterogeneity can induce overdispersion \cite{Gillespie1984}, while temporal rate shifts complicate calibrations that presume uniformity \cite{Ho2011}. External factors, episodic selection, and calibration errors further exacerbate these biases, stressing the importance of careful model selection, robust calibrations, and thorough statistical analyses. To address these challenges, refined techniques such as penalized likelihood, correlated and uncorrelated relaxed clocks, life-history trait covariates, and partitioned models for distinct genes have been developed. Although these approaches mitigate biases, they can be computationally demanding when handling extensive datasets. Despite these hurdles, the molecular clock remains invaluable for reconstructing deep evolutionary timelines and guiding phylodynamic studies of fast-evolving pathogens, highlighting both its enduring utility and the necessity for ongoing methodological improvements. In many instances, studies of RNA viruses offer particularly clear examples of these principles.


\section{Viruses as complex gene expression programs: RNA viruses as a case study}
RNA viruses exhibit exceptionally high mutation rates and rapid replication dynamics that render them ideal models for testing molecular clock hypotheses. A virus's genomic architecture is composed of multiple genes, many of which are multifunctional, that form a complex regulatory circuit with numerous interactions with the host cell. In combination with their intricate regulatory circuitry, these mutations set the stage for swift evolutionary divergence. Moreover, their short generation times and large population sizes further facilitate measurable divergence, producing a clear temporal signal in their genome sequences \cite{Holmes2009}. Consequently, RNA viruses are classified as `measurably evolving populations'', where genetic divergence correlates directly with elapsed time, enabling precise calibration of molecular clocks \cite{Grenfell2004}. This real-time evolution provides a natural laboratory for studying substitution rate variability, selective pressures, and the underlying dynamics of sequence evolution. As such, researchers can rigorously test and refine theoretical models by directly observing evolutionary processes over short time scales, thereby bridging theoretical frameworks with empirical data. Continuous monitoring of viral genomes not only validates molecular clock assumptions but also enhances our understanding of broader evolutionary and epidemiological phenomena, underscoring the critical role these viruses play in advancing molecular evolutionary research.

In the realm of public health, RNA viruses represent significant threats due to their rapid evolution and widespread transmission, as exemplified by the ongoing SARS-CoV-2 pandemic. High-throughput sequencing technologies have revolutionized viral surveillance by enabling rapid, cost-effective sequencing of whole genomes directly from clinical samples. This surge in genomic data empowers researchers to perform time-resolved phylogenetic analyses and robust mathematical modeling, which are crucial for understanding transmission dynamics and predicting epidemic trends \cite{Grubaugh2019, Pollett2020}. Phylodynamic approaches integrate evolutionary data to infer key epidemiological parameters such as outbreak origins, transmission rates, and timing of introductions. These models have been instrumental in guiding interventions, ranging from travel restrictions and quarantine measures to vaccine deployment strategies. Specifically, SARS-CoV-2 has been extensively monitored using millions of genome sequences, allowing scientists to track the emergence and spread of variants in near real-time. The integration of genomic and epidemiological metadata further enhances forecasting capabilities, ensuring that public health responses are both timely and data-driven \cite{Hill2021, Gire2014, Luksza2014}.


\section{Research Gaps and Motivation}
Despite significant advances, evolutionary models remain limited by simplifying assumptions that may not fully capture complex biological realities. Classical models often assume independent loci, constant selection pressures, or simplified recombination dynamics, yet empirical studies reveal pervasive epistasis, variable selection, and linkage effects that challenge these assumptions \cite{lunzer2010pervasive, neher2009competition}. Refining models to incorporate these factors requires a balance between mathematical tractability and biological realism. Recent approaches leverage stochastic processes, Bayesian inference, and simulation-based methods to enhance predictive accuracy \cite{csillery2010approximate, meyer2017accelerating}. However, the stochastic frameworks employed in these models typically incorporate white noise, Gaussian delta-correlated fluctuations, due to its mathematical convenience. While this choice has facilitated substantial advances, it may not capture the full complexity of biological systems. There is growing reason to believe that alternative, more intricate noise models could more accurately represent the stochasticity inherent in evolutionary processes. Furthermore, computational demands grow exponentially, necessitating efficient algorithms and scalable implementations.


Addressing these challenges requires an interdisciplinary approach that integrates evolutionary theory, applied mathematics, and computer science. Advances in Monte Carlo simulations, machine learning, and high-performance computing now enable inference of complex models, but accessibility remains a concern \cite{bryant2017special}. Open-source software plays a pivotal role in democratizing these tools, ensuring reproducibility and fostering collaboration \cite{bouckaert2014beast, haller2019slim}. Platforms such as BEAST, SLiM, and Approximate Bayesian Computation (ABC) frameworks exemplify how theoretical models can be practically implemented for real-world data analysis. The ongoing challenge lies in developing flexible, scalable, and biologically realistic models that bridge theoretical derivations with empirical data, ultimately refining our understanding of molecular evolution.

\bibliographystyle{assets/rodrigostyle}
\bibliography{references/introductionReferences}
